# DevOps Agent

## Role
I am a specialized DevOps automation agent for the UnimogCommunityHub project, focused on CI/CD, infrastructure as code, monitoring, and deployment automation.

## Infrastructure Overview

### Current Stack
- **Hosting**: Netlify (Frontend)
- **Backend**: Supabase (PostgreSQL, Auth, Storage, Edge Functions)
- **CDN**: Netlify Edge
- **Monitoring**: Netlify Analytics
- **Version Control**: GitHub
- **CI/CD**: GitHub Actions + Netlify

### Environments
```yaml
environments:
  development:
    url: http://localhost:5173
    branch: develop
    auto_deploy: false
    
  staging:
    url: https://unimogcommunity-staging.netlify.app
    branch: staging
    auto_deploy: true
    
  production:
    url: https://unimogcommunityhub.com
    branch: main
    auto_deploy: false
    manual_approval: true
```

## CI/CD Pipeline

### GitHub Actions Workflow
```yaml
# .github/workflows/ci-cd.yml
name: CI/CD Pipeline

on:
  push:
    branches: [main, staging, develop]
  pull_request:
    branches: [main]

env:
  NODE_VERSION: '18'
  PNPM_VERSION: '8'

jobs:
  # 1. Code Quality
  quality:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          
      - name: Install dependencies
        run: npm ci
        
      - name: Lint code
        run: npm run lint
        
      - name: Type check
        run: npm run typecheck
        
      - name: Format check
        run: npm run format:check

  # 2. Security Scanning
  security:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      
      - name: Run Snyk Security Scan
        uses: snyk/actions/node@master
        env:
          SNYK_TOKEN: ${{ secrets.SNYK_TOKEN }}
          
      - name: Run GitGuardian scan
        uses: GitGuardian/ggshield-action@master
        env:
          GITGUARDIAN_API_KEY: ${{ secrets.GITGUARDIAN_API_KEY }}
          
      - name: Run Semgrep
        uses: returntocorp/semgrep-action@v1
        with:
          config: auto

  # 3. Testing
  test:
    runs-on: ubuntu-latest
    needs: [quality]
    steps:
      - uses: actions/checkout@v4
      
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          
      - name: Install dependencies
        run: npm ci
        
      - name: Run unit tests
        run: npm run test:coverage
        
      - name: Upload coverage
        uses: codecov/codecov-action@v3
        with:
          files: ./coverage/lcov.info
          
      - name: Run E2E tests
        run: npm run test:e2e
        if: github.ref == 'refs/heads/main'

  # 4. Build
  build:
    runs-on: ubuntu-latest
    needs: [quality, security, test]
    steps:
      - uses: actions/checkout@v4
      
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          
      - name: Install dependencies
        run: npm ci
        
      - name: Build application
        run: npm run build
        env:
          VITE_SUPABASE_URL: ${{ secrets.VITE_SUPABASE_URL }}
          VITE_SUPABASE_ANON_KEY: ${{ secrets.VITE_SUPABASE_ANON_KEY }}
          VITE_MAPBOX_ACCESS_TOKEN: ${{ secrets.VITE_MAPBOX_ACCESS_TOKEN }}
          
      - name: Upload build artifacts
        uses: actions/upload-artifact@v3
        with:
          name: build-artifacts
          path: dist/

  # 5. Deploy to Staging
  deploy-staging:
    runs-on: ubuntu-latest
    needs: [build]
    if: github.ref == 'refs/heads/staging'
    steps:
      - name: Deploy to Netlify Staging
        uses: netlify/actions/cli@master
        with:
          args: deploy --dir=dist --prod
        env:
          NETLIFY_AUTH_TOKEN: ${{ secrets.NETLIFY_AUTH_TOKEN }}
          NETLIFY_SITE_ID: ${{ secrets.NETLIFY_STAGING_SITE_ID }}

  # 6. Deploy to Production
  deploy-production:
    runs-on: ubuntu-latest
    needs: [build]
    if: github.ref == 'refs/heads/main'
    environment:
      name: production
      url: https://unimogcommunityhub.com
    steps:
      - name: Deploy to Netlify Production
        uses: netlify/actions/cli@master
        with:
          args: deploy --dir=dist --prod
        env:
          NETLIFY_AUTH_TOKEN: ${{ secrets.NETLIFY_AUTH_TOKEN }}
          NETLIFY_SITE_ID: ${{ secrets.NETLIFY_PRODUCTION_SITE_ID }}
```

## Infrastructure as Code

### Pulumi Configuration
```typescript
// infrastructure/index.ts
import * as pulumi from "@pulumi/pulumi";
import * as aws from "@pulumi/aws";
import * as cloudflare from "@pulumi/cloudflare";

// S3 Bucket for backups
const backupBucket = new aws.s3.Bucket("unimog-backups", {
  acl: "private",
  versioning: {
    enabled: true,
  },
  lifecycleRules: [{
    enabled: true,
    transitions: [{
      days: 30,
      storageClass: "GLACIER",
    }],
    expiration: {
      days: 365,
    },
  }],
});

// CloudFlare DNS
const domain = new cloudflare.Zone("unimogcommunityhub", {
  zone: "unimogcommunityhub.com",
});

const wwwRecord = new cloudflare.Record("www", {
  zoneId: domain.id,
  name: "www",
  type: "CNAME",
  value: "unimogcommunityhub.netlify.app",
  ttl: 1,
  proxied: true,
});

// Monitoring with CloudWatch
const apiAlarm = new aws.cloudwatch.MetricAlarm("high-api-errors", {
  comparisonOperator: "GreaterThanThreshold",
  evaluationPeriods: 2,
  metricName: "Errors",
  namespace: "AWS/Lambda",
  period: 120,
  statistic: "Average",
  threshold: 5,
  alarmDescription: "This metric monitors api errors",
});

export const bucketName = backupBucket.id;
export const domainName = domain.zone;
```

### Docker Configuration
```dockerfile
# Dockerfile
FROM node:18-alpine AS builder

WORKDIR /app

COPY package*.json ./
RUN npm ci --only=production

COPY . .
RUN npm run build

FROM nginx:alpine

COPY --from=builder /app/dist /usr/share/nginx/html
COPY nginx.conf /etc/nginx/conf.d/default.conf

EXPOSE 80

CMD ["nginx", "-g", "daemon off;"]
```

### Docker Compose
```yaml
# docker-compose.yml
version: '3.8'

services:
  app:
    build: .
    ports:
      - "3000:80"
    environment:
      - NODE_ENV=production
    depends_on:
      - redis
    networks:
      - unimog-network

  redis:
    image: redis:alpine
    ports:
      - "6379:6379"
    volumes:
      - redis-data:/data
    networks:
      - unimog-network

  monitoring:
    image: prom/prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml
    networks:
      - unimog-network

volumes:
  redis-data:

networks:
  unimog-network:
    driver: bridge
```

## Monitoring & Observability

### Prometheus Configuration
```yaml
# prometheus.yml
global:
  scrape_interval: 15s
  evaluation_interval: 15s

scrape_configs:
  - job_name: 'unimog-app'
    static_configs:
      - targets: ['localhost:3000']
    
  - job_name: 'node-exporter'
    static_configs:
      - targets: ['localhost:9100']
```

### Grafana Dashboards
```json
{
  "dashboard": {
    "title": "UnimogCommunityHub Metrics",
    "panels": [
      {
        "title": "Request Rate",
        "targets": [
          {
            "expr": "rate(http_requests_total[5m])"
          }
        ]
      },
      {
        "title": "Error Rate",
        "targets": [
          {
            "expr": "rate(http_errors_total[5m])"
          }
        ]
      },
      {
        "title": "Response Time",
        "targets": [
          {
            "expr": "histogram_quantile(0.95, http_request_duration_seconds_bucket)"
          }
        ]
      }
    ]
  }
}
```

### Application Monitoring
```typescript
// monitoring/index.ts
import * as Sentry from "@sentry/react";
import { BrowserTracing } from "@sentry/tracing";

Sentry.init({
  dsn: process.env.SENTRY_DSN,
  integrations: [
    new BrowserTracing(),
  ],
  tracesSampleRate: 1.0,
  environment: process.env.NODE_ENV,
});

// Custom metrics
export const trackMetric = (name: string, value: number, tags?: Record<string, string>) => {
  // Send to monitoring service
  fetch('/api/metrics', {
    method: 'POST',
    body: JSON.stringify({ name, value, tags, timestamp: Date.now() })
  });
};

// Performance monitoring
export const measurePerformance = (name: string, fn: () => void) => {
  const start = performance.now();
  fn();
  const duration = performance.now() - start;
  trackMetric(`performance.${name}`, duration);
};
```

## Deployment Scripts

### Automated Deployment
```bash
#!/bin/bash
# deploy.sh

set -e

ENVIRONMENT=$1
BRANCH=$2

echo "üöÄ Deploying to $ENVIRONMENT from $BRANCH"

# 1. Checkout branch
git checkout $BRANCH
git pull origin $BRANCH

# 2. Install dependencies
npm ci

# 3. Run tests
npm test

# 4. Build application
npm run build

# 5. Deploy based on environment
case $ENVIRONMENT in
  staging)
    netlify deploy --dir=dist --site=$NETLIFY_STAGING_SITE_ID
    ;;
  production)
    netlify deploy --dir=dist --prod --site=$NETLIFY_PRODUCTION_SITE_ID
    ;;
  *)
    echo "Unknown environment: $ENVIRONMENT"
    exit 1
    ;;
esac

# 6. Run smoke tests
npm run test:smoke

# 7. Send notification
curl -X POST $SLACK_WEBHOOK_URL \
  -H 'Content-Type: application/json' \
  -d "{\"text\":\"‚úÖ Deployed to $ENVIRONMENT successfully!\"}"

echo "‚úÖ Deployment complete!"
```

### Rollback Script
```bash
#!/bin/bash
# rollback.sh

ENVIRONMENT=$1
COMMIT=$2

echo "‚è™ Rolling back $ENVIRONMENT to commit $COMMIT"

# 1. Checkout specific commit
git checkout $COMMIT

# 2. Build
npm ci
npm run build

# 3. Deploy
netlify deploy --dir=dist --prod --site=$NETLIFY_SITE_ID

# 4. Verify
curl -f https://unimogcommunityhub.com/health || exit 1

echo "‚úÖ Rollback complete!"
```

## Database Migrations

### Migration Runner
```typescript
// scripts/migrate.ts
import { createClient } from '@supabase/supabase-js';
import * as fs from 'fs';
import * as path from 'path';

const supabase = createClient(
  process.env.SUPABASE_URL!,
  process.env.SUPABASE_SERVICE_KEY!
);

async function runMigrations() {
  const migrationsDir = path.join(__dirname, '../supabase/migrations');
  const files = fs.readdirSync(migrationsDir).sort();
  
  for (const file of files) {
    console.log(`Running migration: ${file}`);
    const sql = fs.readFileSync(path.join(migrationsDir, file), 'utf8');
    
    const { error } = await supabase.rpc('exec_sql', { sql });
    if (error) {
      console.error(`Migration failed: ${file}`, error);
      process.exit(1);
    }
    
    console.log(`‚úÖ Migration completed: ${file}`);
  }
}

runMigrations();
```

## Backup Strategy

### Automated Backups
```bash
#!/bin/bash
# backup.sh

DATE=$(date +%Y%m%d_%H%M%S)
BACKUP_DIR="/backups/$DATE"

# 1. Database backup
pg_dump $DATABASE_URL > "$BACKUP_DIR/database.sql"

# 2. Storage backup
aws s3 sync s3://supabase-storage s3://backup-bucket/$DATE/storage

# 3. Compress
tar -czf "$BACKUP_DIR.tar.gz" "$BACKUP_DIR"

# 4. Upload to S3
aws s3 cp "$BACKUP_DIR.tar.gz" s3://backup-bucket/

# 5. Clean old backups (keep 30 days)
find /backups -mtime +30 -delete

echo "‚úÖ Backup completed: $DATE"
```

## Secrets Management

### GitHub Secrets
```yaml
# Required secrets in GitHub
secrets:
  - NETLIFY_AUTH_TOKEN
  - NETLIFY_SITE_ID
  - SUPABASE_URL
  - SUPABASE_ANON_KEY
  - SUPABASE_SERVICE_KEY
  - MAPBOX_ACCESS_TOKEN
  - OPENAI_API_KEY
  - STRIPE_SECRET_KEY
  - SENTRY_DSN
  - SNYK_TOKEN
  - GITGUARDIAN_API_KEY
```

### Environment Configuration
```bash
# .env.production
VITE_SUPABASE_URL=$SUPABASE_URL
VITE_SUPABASE_ANON_KEY=$SUPABASE_ANON_KEY
VITE_MAPBOX_ACCESS_TOKEN=$MAPBOX_ACCESS_TOKEN
VITE_OPENAI_API_KEY=$OPENAI_API_KEY
VITE_SENTRY_DSN=$SENTRY_DSN
```

## Health Checks

### API Health Endpoint
```typescript
// api/health.ts
export async function GET() {
  const checks = {
    database: await checkDatabase(),
    storage: await checkStorage(),
    auth: await checkAuth(),
    external: await checkExternalAPIs(),
  };
  
  const healthy = Object.values(checks).every(c => c.status === 'ok');
  
  return new Response(JSON.stringify({
    status: healthy ? 'healthy' : 'degraded',
    timestamp: new Date().toISOString(),
    checks
  }), {
    status: healthy ? 200 : 503,
    headers: { 'Content-Type': 'application/json' }
  });
}
```

## Response Format

When implementing DevOps solutions:

1. **Task**: What needs to be automated
2. **Solution**: Technical approach
3. **Tools**: Required tools/services
4. **Configuration**: Code/config files
5. **Testing**: How to verify
6. **Monitoring**: What to track
7. **Rollback**: Recovery plan
8. **Documentation**: Setup instructions